#!/usr/bin/env python3
"""
Grade 6 Lower Quests ç”Ÿæˆè„šæœ¬
æ ¹æ®æ¯ä¸ªå•å…ƒçš„wordsã€phrasesã€patternsè‡ªåŠ¨ç”Ÿæˆæ ‡å‡†æ ¼å¼çš„questså†…å®¹

ç”Ÿæˆçš„questsåŒ…å«4ç§ç±»å‹ï¼š
1. vocabulary-matching - è¯è¯­é…å¯¹ç»ƒä¹ 
2. sentence-sorting - è¯è¯­æ’åºç»ƒä¹ 
3. en-to-zh - è‹±ç¿»ä¸­ç»ƒä¹ 
4. zh-to-en - ä¸­ç¿»è‹±ç»ƒä¹ 
"""

import json
import os
import re
from pathlib import Path
from typing import Dict, List, Any, Tuple
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class QuestGenerator:
    """Questå†…å®¹ç”Ÿæˆå™¨"""

    def __init__(self, content_dir: str):
        self.content_dir = Path(content_dir)

    def generate_filename_from_text(self, text: str) -> str:
        """ä»æ–‡æœ¬ç”Ÿæˆæ–‡ä»¶å"""
        filename = text.lower()
        filename = re.sub(r'[^\w\s-]', '', filename)
        filename = re.sub(r'\s+', '-', filename)
        filename = re.sub(r'-+', '-', filename)
        filename = filename.strip('-')
        return filename + ".mp3"

    def split_chinese_sentence(self, sentence: str) -> List[str]:
        """æ™ºèƒ½åˆ†å‰²ä¸­æ–‡å¥å­ï¼Œå°†æ ‡ç‚¹ç¬¦å·ç‹¬ç«‹å¤„ç†

        Args:
            sentence: ä¸­æ–‡å¥å­ï¼Œå¦‚"ä½ åœ¨åšä»€ä¹ˆï¼Ÿ"

        Returns:
            åˆ†å‰²åçš„è¯è¯­åˆ—è¡¨ï¼Œå¦‚["ä½ ", "åœ¨", "åšä»€ä¹ˆ", "ï¼Ÿ"]
        """
        import re

        # ä¸­æ–‡æ ‡ç‚¹ç¬¦å·é›†åˆ
        chinese_punctuation = r'[ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹ã€]'

        # ç¬¬ä¸€æ­¥ï¼šæå–å¹¶åˆ†å‰²æ ‡ç‚¹ç¬¦å·
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ‰¾åˆ°æ‰€æœ‰æ ‡ç‚¹ç¬¦å·çš„ä½ç½®
        punctuation_pattern = f'({chinese_punctuation})'
        parts = re.split(punctuation_pattern, sentence)

        # ç¬¬äºŒæ­¥ï¼šå¤„ç†éæ ‡ç‚¹ç¬¦å·éƒ¨åˆ†ï¼ŒæŒ‰è¯è¯­åˆ†å‰²
        result = []
        for part in parts:
            if not part:  # è·³è¿‡ç©ºå­—ç¬¦ä¸²
                continue
            elif re.match(chinese_punctuation, part):  # å¦‚æœæ˜¯æ ‡ç‚¹ç¬¦å·
                result.append(part)
            else:  # å¦‚æœæ˜¯æ–‡å­—éƒ¨åˆ†
                # ç§»é™¤å¯èƒ½çš„ç©ºæ ¼ï¼Œç„¶åæŒ‰å¸¸è§åˆ†è¯è§„åˆ™åˆ†å‰²
                clean_part = part.strip()
                if clean_part:
                    # ç®€å•çš„ä¸­æ–‡åˆ†è¯é€»è¾‘ï¼š
                    # 1. å…ˆå°è¯•æŒ‰ç©ºæ ¼åˆ†å‰²
                    words = clean_part.split()
                    if len(words) > 1:
                        result.extend(words)
                    else:
                        # 2. å¦‚æœæ²¡æœ‰ç©ºæ ¼ï¼Œå°è¯•æŒ‰å¸¸è§çš„è¯è¯­è¾¹ç•Œåˆ†å‰²
                        # è¿™é‡Œä½¿ç”¨å¯å‘å¼æ–¹æ³•ï¼šå¸¸è§çš„è¯è¯­é•¿åº¦ä¸º2-3ä¸ªå­—
                        text = clean_part
                        i = 0
                        while i < len(text):
                            # ä¼˜å…ˆå°è¯•3å­—è¯
                            if i + 3 <= len(text) and text[i:i+3] in ['åšä»€ä¹ˆ', 'å¹²ä»€ä¹ˆ', 'æ€ä¹ˆåš', 'ä¸ºä»€ä¹ˆ', 'æ€ä¹ˆæ ·']:
                                result.append(text[i:i+3])
                                i += 3
                            # ç„¶åå°è¯•2å­—è¯
                            elif i + 2 <= len(text) and text[i:i+2] in ['æˆ‘ä»¬', 'ä½ ä»¬', 'ä»–ä»¬', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'è¿™æ ·', 'é‚£æ ·', 'è¿™é‡Œ', 'é‚£é‡Œ', 'ç°åœ¨', 'æ­£åœ¨', 'å·²ç»', 'å¯ä»¥', 'åº”è¯¥', 'éœ€è¦', 'æƒ³è¦', 'å–œæ¬¢', 'çŸ¥é“', 'æ˜ç™½', 'ç†è§£', 'å­¦ä¹ ', 'å·¥ä½œ', 'ç”Ÿæ´»', 'å›å®¶', 'åƒé¥­', 'ç¡è§‰', 'èµ·åºŠ', 'å‡ºé—¨', 'è¿›é—¨', 'ä¸Šæ¥¼', 'ä¸‹æ¥¼', 'å¼€é—¨', 'å…³é—¨', 'å¼€ç¯', 'å…³ç¯']:
                                result.append(text[i:i+2])
                                i += 2
                            else:
                                # å•å­—å¤„ç†
                                result.append(text[i])
                                i += 1

        # è¿‡æ»¤æ‰ç©ºå­—ç¬¦ä¸²
        result = [word for word in result if word.strip()]

        return result

    def create_vocabulary_matching_quest(self, words: List[Dict], phrases: List[Dict]) -> Dict:
        """åˆ›å»ºè¯è¯­é…å¯¹ç»ƒä¹ """
        # åˆå¹¶wordså’Œphrasesä½œä¸ºé…å¯¹å†…å®¹
        all_pairs = []

        # æ·»åŠ å•è¯é…å¯¹ (6ä¸ª)
        for word in words[:6]:
            if 'en' in word and 'zh' in word:
                all_pairs.append({
                    "en": word['en'],
                    "zh": word['zh']
                })

        # æ·»åŠ çŸ­è¯­é…å¯¹ (6ä¸ª)
        for phrase in phrases[:6]:
            if 'en' in phrase and 'zh' in phrase:
                all_pairs.append({
                    "en": phrase['en'],
                    "zh": phrase['zh']
                })

        # åˆ†æˆ3ä¸ªæ­¥éª¤
        steps = []
        for i in range(0, len(all_pairs), 6):
            step_pairs = all_pairs[i:i+6]
            if len(step_pairs) >= 2:
                # æ·»åŠ å¹²æ‰°é¡¹
                options = []
                for option_word in words[6:8] if len(words) > 8 else words[-2:]:
                    if 'en' in option_word and 'zh' in option_word:
                        options.append({
                            "en": option_word['en'],
                            "zh": option_word['zh']
                        })

                step = {
                    "type": "wordmatching",
                    "text": f"å°†è‹±è¯­å•è¯ä¸çŸ­è¯­é…å¯¹ (ç¬¬{i//6 + 1}éƒ¨åˆ†)",
                    "pairs": step_pairs,
                    "options": options
                }
                steps.append(step)

        return {
            "id": "vocabulary-matching",
            "title": "è¯è¯­é…å¯¹ç»ƒä¹ ",
            "steps": steps,
            "reward": {"badge": "/images/rewards/badge-food.png", "xp": 10}
        }

    def create_sentence_sorting_quest(self, phrases: List[Dict], patterns: List[Dict]) -> Dict:
        """åˆ›å»ºè¯è¯­æ’åºç»ƒä¹ """
        steps = []

        # ä¼˜å…ˆä½¿ç”¨çŸ­è¯­ï¼Œä¸è¶³æ—¶ä½¿ç”¨patterns
        sorting_items = []

        # æ·»åŠ çŸ­è¯­ (3ä¸ª)
        for phrase in phrases[:3]:
            if 'en' in phrase and 'audio' in phrase:
                text = phrase['en']
                words = text.split()
                if len(words) >= 3:
                    # æ‰“ä¹±å•è¯é¡ºåº
                    scrambled = words[1:] + [words[0]]  # ç®€å•æ‰“ä¹±
                    # ä½¿ç”¨çŸ­è¯­ä¸­å·²æœ‰çš„éŸ³é¢‘è·¯å¾„
                    audio_path = phrase['audio']

                    sorting_items.append({
                        "type": "sentencesorting",
                        "text": f"å¬å¥å­å¹¶æŒ‰æ­£ç¡®é¡ºåºæ’åˆ—å•è¯ (ç¬¬{len(sorting_items)+1}éƒ¨åˆ†)",
                        "audio": audio_path,
                        "scrambled": scrambled,
                        "correct": words
                    })

        # æ·»åŠ patterns (å¦‚æœçŸ­è¯­ä¸è¶³)
        if len(sorting_items) < 3:
            for pattern in patterns[:3-len(sorting_items)]:
                if 'q' in pattern:
                    text = pattern['q']
                    words = text.split()
                    if len(words) >= 3:
                        scrambled = words[1:] + [words[0]]
                        filename = self.generate_filename_from_text(text)
                        audio_path = f"/audio/tts/{filename}"

                        sorting_items.append({
                            "type": "sentencesorting",
                            "text": f"å¬å¥å­å¹¶æŒ‰æ­£ç¡®é¡ºåºæ’åˆ—å•è¯ (ç¬¬{len(sorting_items)+1}éƒ¨åˆ†)",
                            "audio": audio_path,
                            "scrambled": scrambled,
                            "correct": words
                        })

        return {
            "id": "sentence-sorting",
            "title": "è¯è¯­æ’åºç»ƒä¹ ",
            "steps": sorting_items,
            "reward": {"badge": "/images/rewards/badge-sentence.png", "xp": 15}
        }

    def create_en_to_zh_quest(self, phrases: List[Dict], patterns: List[Dict]) -> Dict:
        """åˆ›å»ºè‹±ç¿»ä¸­ç»ƒä¹ """
        steps = []

        # ä¼˜å…ˆä½¿ç”¨patternsä¸­çš„æ‰€æœ‰å¥å­
        translation_items = []

        # æ·»åŠ patternsä¸­çš„æ‰€æœ‰å¥å­
        for pattern in patterns:
            if 'q' in pattern and 'a' in pattern:
                chinese_words = self.split_chinese_sentence(pattern['a'])
                if len(chinese_words) >= 2:
                    translation_items.append({
                        "type": "entozh",
                        "text": "å°†è‹±è¯­å¥å­ç¿»è¯‘æˆæ­£ç¡®çš„ä¸­æ–‡é¡ºåº",
                        "english": pattern['q'],
                        "scrambledChinese": chinese_words[1:] + [chinese_words[0]],
                        "correctChinese": chinese_words
                    })

        # å¦‚æœpatternsä¸è¶³ï¼Œè¡¥å……çŸ­è¯­
        if len(translation_items) < 4:  # ç›®æ ‡æ˜¯4ä¸ªç»ƒä¹ 
            for phrase in phrases[:4-len(translation_items)]:
                if 'en' in phrase and 'zh' in phrase:
                    chinese_words = self.split_chinese_sentence(phrase['zh'])
                    if len(chinese_words) >= 2:
                        translation_items.append({
                            "type": "entozh",
                            "text": "å°†è‹±è¯­å¥å­ç¿»è¯‘æˆæ­£ç¡®çš„ä¸­æ–‡é¡ºåº",
                            "english": phrase['en'],
                            "scrambledChinese": chinese_words[1:] + [chinese_words[0]],
                            "correctChinese": chinese_words
                        })

        return {
            "id": "en-to-zh",
            "title": "è‹±ç¿»ä¸­ç»ƒä¹ ",
            "steps": translation_items[:4],  # æœ€å¤š4ä¸ªç»ƒä¹ 
            "reward": {"badge": "/images/rewards/badge-translate.png", "xp": 15}
        }

    def create_zh_to_en_quest(self, phrases: List[Dict], patterns: List[Dict]) -> Dict:
        """åˆ›å»ºä¸­ç¿»è‹±ç»ƒä¹ """
        steps = []

        # ä¼˜å…ˆä½¿ç”¨patternsä¸­çš„æ‰€æœ‰å¥å­
        translation_items = []

        # æ·»åŠ patternsä¸­çš„æ‰€æœ‰å¥å­
        for pattern in patterns:
            if 'q' in pattern and 'a' in pattern:
                english_words = pattern['q'].split()
                if len(english_words) >= 2:
                    translation_items.append({
                        "type": "zhtoen",
                        "text": "å°†ä¸­æ–‡å¥å­ç¿»è¯‘æˆæ­£ç¡®çš„è‹±æ–‡å•è¯é¡ºåº",
                        "chinese": pattern['a'],
                        "scrambledEnglish": english_words[1:] + [english_words[0]],
                        "correctEnglish": english_words
                    })

        # å¦‚æœpatternsä¸è¶³ï¼Œè¡¥å……çŸ­è¯­
        if len(translation_items) < 4:  # ç›®æ ‡æ˜¯4ä¸ªç»ƒä¹ 
            for phrase in phrases[:4-len(translation_items)]:
                if 'en' in phrase and 'zh' in phrase:
                    english_words = phrase['en'].split()
                    if len(english_words) >= 2:
                        translation_items.append({
                            "type": "zhtoen",
                            "text": "å°†ä¸­æ–‡å¥å­ç¿»è¯‘æˆæ­£ç¡®çš„è‹±æ–‡å•è¯é¡ºåº",
                            "chinese": phrase['zh'],
                            "scrambledEnglish": english_words[1:] + [english_words[0]],
                            "correctEnglish": english_words
                        })

        return {
            "id": "zh-to-en",
            "title": "ä¸­ç¿»è‹±ç»ƒä¹ ",
            "steps": translation_items[:4],  # æœ€å¤š4ä¸ªç»ƒä¹ 
            "reward": {"badge": "/images/rewards/badge-language.png", "xp": 15}
        }

    def generate_quests_for_module(self, module_data: Dict) -> List[Dict]:
        """ä¸ºå•ä¸ªæ¨¡å—ç”Ÿæˆquests"""
        words = module_data.get('words', [])
        phrases = module_data.get('phrases', [])
        patterns = module_data.get('patterns', [])

        quests = []

        # 1. è¯è¯­é…å¯¹ç»ƒä¹  (æ€»æ˜¯ç”Ÿæˆ)
        vocab_quest = self.create_vocabulary_matching_quest(words, phrases)
        if vocab_quest['steps']:
            quests.append(vocab_quest)

        # 2. è¯è¯­æ’åºç»ƒä¹  (æ€»æ˜¯ç”Ÿæˆ)
        sorting_quest = self.create_sentence_sorting_quest(phrases, patterns)
        if sorting_quest['steps']:
            quests.append(sorting_quest)

        # 3. è‹±ç¿»ä¸­ç»ƒä¹  (æ€»æ˜¯ç”Ÿæˆï¼Œä¼˜å…ˆè¦†ç›–patterns)
        en_to_zh_quest = self.create_en_to_zh_quest(phrases, patterns)
        if en_to_zh_quest['steps']:
            quests.append(en_to_zh_quest)

        # 4. ä¸­ç¿»è‹±ç»ƒä¹  (æ€»æ˜¯ç”Ÿæˆï¼Œä¼˜å…ˆè¦†ç›–patterns)
        zh_to_en_quest = self.create_zh_to_en_quest(phrases, patterns)
        if zh_to_en_quest['steps']:
            quests.append(zh_to_en_quest)

        return quests

    def update_grade6_lower_modules(self):
        """æ›´æ–°æŒ‡å®šçš„å…­å¹´çº§ä¸‹å†Œæ¨¡å—çš„quests"""
        # æŒ‡å®šçš„10ä¸ªå…­å¹´çº§ä¸‹å†Œæ–‡ä»¶
        grade6_lower_files = [
            "grade6-lower-mod-01-ordering-food.json",
            "grade6-lower-mod-02-plans-and-weather.json",
            "grade6-lower-mod-03-past-events.json",
            "grade6-lower-mod-04-describing-actions.json",
            "grade6-lower-mod-05-simultaneous-actions.json",
            "grade6-lower-mod-06-gifts-and-past-actions.json",
            "grade6-lower-mod-07-famous-people.json",
            "grade6-lower-mod-08-asking-why.json",
            "grade6-lower-mod-09-best-wishes.json",
            "grade6-lower-mod-10-future-school-life.json"
        ]

        updated_files = []
        skipped_files = []
        error_files = []

        for file_name in grade6_lower_files:
            file_path = self.content_dir / file_name

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not file_path.exists():
                logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_name}")
                skipped_files.append(file_name)
                continue

            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    module_data = json.load(f)

                # ç”Ÿæˆæ–°çš„quests
                new_quests = self.generate_quests_for_module(module_data)

                if new_quests:
                    # å¤‡ä»½åŸæ–‡ä»¶
                    backup_path = file_path.with_suffix('.json.backup')
                    with open(backup_path, 'w', encoding='utf-8') as f:
                        json.dump(module_data, f, ensure_ascii=False, indent=2)

                    # æ›´æ–°quests
                    module_data['quests'] = new_quests

                    # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
                    with open(file_path, 'w', encoding='utf-8') as f:
                        json.dump(module_data, f, ensure_ascii=False, indent=2)

                    updated_files.append(file_name)
                    logger.info(f"âœ… æ›´æ–°å®Œæˆ: {file_name} (ç”Ÿæˆ {len(new_quests)} ä¸ªquests)")
                else:
                    skipped_files.append(file_name)
                    logger.warning(f"âš ï¸ è·³è¿‡: {file_name} (å†…å®¹ä¸è¶³)")

            except Exception as e:
                error_files.append(file_name)
                logger.error(f"âŒ å¤„ç†å¤±è´¥ {file_name}: {e}")

        logger.info(f"\nğŸ“Š å¤„ç†å®Œæˆ:")
        logger.info(f"   æ›´æ–°æ–‡ä»¶: {len(updated_files)}")
        logger.info(f"   è·³è¿‡æ–‡ä»¶: {len(skipped_files)}")
        logger.info(f"   é”™è¯¯æ–‡ä»¶: {len(error_files)}")

        return updated_files, skipped_files, error_files

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="Grade 6 Lower Questsç”Ÿæˆå™¨")
    parser.add_argument("--content-dir", default="src/content", help="å†…å®¹ç›®å½•è·¯å¾„")
    parser.add_argument("--dry-run", action="store_true", help="é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶")

    args = parser.parse_args()

    content_dir = Path(args.content_dir)
    if not content_dir.exists():
        logger.error(f"âŒ å†…å®¹ç›®å½•ä¸å­˜åœ¨: {content_dir}")
        return 1

    logger.info("ğŸš€ å¼€å§‹ä¸ºå…­å¹´çº§ä¸‹å†Œæ¨¡å—ç”Ÿæˆquests...")
    logger.info(f"ğŸ“ å†…å®¹ç›®å½•: {content_dir}")

    if args.dry_run:
        logger.info("ğŸ” é¢„è§ˆæ¨¡å¼ - ä¸ä¼šä¿®æ”¹å®é™…æ–‡ä»¶")

    generator = QuestGenerator(str(content_dir))

    if not args.dry_run:
        updated_files, skipped_files, error_files = generator.update_grade6_lower_modules()

        logger.info(f"\nâœ… æˆåŠŸæ›´æ–°çš„æ–‡ä»¶:")
        for file_name in updated_files:
            logger.info(f"   - {file_name}")

        if skipped_files:
            logger.info(f"\nâš ï¸ è·³è¿‡çš„æ–‡ä»¶:")
            for file_name in skipped_files:
                logger.info(f"   - {file_name}")

        if error_files:
            logger.info(f"\nâŒ å¤„ç†å¤±è´¥çš„æ–‡ä»¶:")
            for file_name in error_files:
                logger.info(f"   - {file_name}")
    else:
        # é¢„è§ˆæ¨¡å¼ï¼šåªæ˜¾ç¤ºå°†è¦å¤„ç†çš„æ–‡ä»¶
        grade6_files = [
            "grade6-lower-mod-01-ordering-food.json",
            "grade6-lower-mod-02-plans-and-weather.json",
            "grade6-lower-mod-03-past-events.json",
            "grade6-lower-mod-04-describing-actions.json",
            "grade6-lower-mod-05-simultaneous-actions.json",
            "grade6-lower-mod-06-gifts-and-past-actions.json",
            "grade6-lower-mod-07-famous-people.json",
            "grade6-lower-mod-08-asking-why.json",
            "grade6-lower-mod-09-best-wishes.json",
            "grade6-lower-mod-10-future-school-life.json"
        ]
        logger.info(f"ğŸ“‹ å°†è¦å¤„ç† {len(grade6_files)} ä¸ªæ–‡ä»¶:")
        for file_name in grade6_files:
            file_path = content_dir / file_name
            exists = "âœ…" if file_path.exists() else "âŒ"
            logger.info(f"   {exists} - {file_name}")

    logger.info("\nğŸ‰ Questsç”Ÿæˆå®Œæˆ!")
    return 0

if __name__ == "__main__":
    exit(main())
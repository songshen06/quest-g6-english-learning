#!/usr/bin/env python3
"""
Quest Patterns è¦†ç›–æ£€æŸ¥å’Œä¿®å¤å·¥å…·

åŠŸèƒ½ï¼š
1. æ£€æŸ¥æ‰€æœ‰JSONæ¨¡å—æ–‡ä»¶çš„questsæ˜¯å¦å®Œå…¨è¦†ç›–äº†patternsä¸­çš„å¥å­
2. è‡ªåŠ¨ä¿®å¤ä¸ç¬¦åˆè¦æ±‚çš„quests
3. ç”Ÿæˆè¯¦ç»†çš„æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
python ensure_pattern_coverage.py [--dry-run] [--content-dir src/content]

å‚æ•°ï¼š
--dry-run: é¢„è§ˆæ¨¡å¼ï¼Œåªæ£€æŸ¥ä¸ä¿®å¤
--content-dir: æŒ‡å®šå†…å®¹ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸º src/content
"""

import json
import os
import re
from pathlib import Path
from typing import Dict, List, Any, Set, Tuple
import logging
import argparse
from datetime import datetime

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class PatternCoverageChecker:
    """Patternsè¦†ç›–æ£€æŸ¥å’Œä¿®å¤å™¨"""

    def __init__(self, content_dir: str):
        self.content_dir = Path(content_dir)
        self.report = {
            'timestamp': datetime.now().isoformat(),
            'total_files': 0,
            'files_with_patterns': 0,
            'files_with_complete_coverage': 0,
            'files_needing_repair': 0,
            'details': []
        }

    def generate_filename_from_text(self, text: str) -> str:
        """ä»æ–‡æœ¬ç”Ÿæˆæ–‡ä»¶å"""
        filename = text.lower()
        filename = re.sub(r'[^\w\s-]', '', filename)
        filename = re.sub(r'\s+', '-', filename)
        filename = re.sub(r'-+', '-', filename)
        filename = filename.strip('-')
        return filename + ".mp3"

    def extract_covered_patterns(self, quests: List[Dict]) -> Set[Tuple[str, str]]:
        """ä»questsä¸­æå–å·²è¦†ç›–çš„patterns (q, a) pairs"""
        covered = set()

        for quest in quests:
            if quest.get('id') in ['en-to-zh', 'zh-to-en']:
                for step in quest.get('steps', []):
                    if step.get('type') == 'entozh':
                        # è‹±ç¿»ä¸­ç»ƒä¹ 
                        english = step.get('english', '')
                        chinese = step.get('correctChinese', [])
                        if english and chinese:
                            chinese_text = ' '.join(chinese)
                            covered.add((english, chinese_text))

                    elif step.get('type') == 'zhtoen':
                        # ä¸­ç¿»è‹±ç»ƒä¹ 
                        chinese = step.get('chinese', '')
                        english = step.get('correctEnglish', [])
                        if chinese and english:
                            english_text = ' '.join(english)
                            covered.add((english_text, chinese))

        return covered

    def create_vocabulary_matching_quest(self, words: List[Dict], phrases: List[Dict]) -> Dict:
        """åˆ›å»ºè¯è¯­é…å¯¹ç»ƒä¹ """
        all_pairs = []

        # æ·»åŠ å•è¯é…å¯¹ (6ä¸ª)
        for word in words[:6]:
            if 'en' in word and 'zh' in word:
                all_pairs.append({
                    "en": word['en'],
                    "zh": word['zh']
                })

        # æ·»åŠ çŸ­è¯­é…å¯¹ (6ä¸ª)
        for phrase in phrases[:6]:
            if 'en' in phrase and 'zh' in phrase:
                all_pairs.append({
                    "en": phrase['en'],
                    "zh": phrase['zh']
                })

        # åˆ†æˆå¤šä¸ªæ­¥éª¤
        steps = []
        for i in range(0, len(all_pairs), 6):
            step_pairs = all_pairs[i:i+6]
            if len(step_pairs) >= 2:
                # æ·»åŠ å¹²æ‰°é¡¹
                options = []
                for option_word in words[6:8] if len(words) > 8 else words[-2:]:
                    if 'en' in option_word and 'zh' in option_word:
                        options.append({
                            "en": option_word['en'],
                            "zh": option_word['zh']
                        })

                step = {
                    "type": "wordmatching",
                    "text": f"å°†è‹±è¯­å•è¯ä¸çŸ­è¯­é…å¯¹ (ç¬¬{i//6 + 1}éƒ¨åˆ†)",
                    "pairs": step_pairs,
                    "options": options
                }
                steps.append(step)

        return {
            "id": "vocabulary-matching",
            "title": "è¯è¯­é…å¯¹ç»ƒä¹ ",
            "steps": steps,
            "reward": {"badge": "/images/rewards/vocabulary-badge.png", "xp": 10}
        }

    def create_sentence_sorting_quest(self, phrases: List[Dict], patterns: List[Dict]) -> Dict:
        """åˆ›å»ºè¯è¯­æ’åºç»ƒä¹ """
        sorting_items = []

        # æ·»åŠ çŸ­è¯­
        for phrase in phrases[:3]:
            if 'en' in phrase and 'audio' in phrase:
                text = phrase['en']
                words = text.split()
                if len(words) >= 3:
                    scrambled = words[1:] + [words[0]]
                    audio_path = phrase['audio']

                    sorting_items.append({
                        "type": "sentencesorting",
                        "text": f"å¬å¥å­å¹¶æŒ‰æ­£ç¡®é¡ºåºæ’åˆ—å•è¯ (ç¬¬{len(sorting_items)+1}éƒ¨åˆ†)",
                        "audio": audio_path,
                        "scrambled": scrambled,
                        "correct": words
                    })

        # æ·»åŠ patterns (å¦‚æœçŸ­è¯­ä¸è¶³)
        if len(sorting_items) < 3:
            for pattern in patterns[:3-len(sorting_items)]:
                if 'q' in pattern:
                    text = pattern['q']
                    words = text.split()
                    if len(words) >= 3:
                        scrambled = words[1:] + [words[0]]
                        filename = self.generate_filename_from_text(text)
                        audio_path = f"/audio/tts/{filename}"

                        sorting_items.append({
                            "type": "sentencesorting",
                            "text": f"å¬å¥å­å¹¶æŒ‰æ­£ç¡®é¡ºåºæ’åˆ—å•è¯ (ç¬¬{len(sorting_items)+1}éƒ¨åˆ†)",
                            "audio": audio_path,
                            "scrambled": scrambled,
                            "correct": words
                        })

        return {
            "id": "sentence-sorting",
            "title": "è¯è¯­æ’åºç»ƒä¹ ",
            "steps": sorting_items,
            "reward": {"badge": "/images/rewards/sorting-badge.png", "xp": 15}
        }

    def create_en_to_zh_quest(self, phrases: List[Dict], patterns: List[Dict]) -> Dict:
        """åˆ›å»ºè‹±ç¿»ä¸­ç»ƒä¹  - ä¼˜å…ˆè¦†ç›–æ‰€æœ‰patterns"""
        translation_items = []

        # æ·»åŠ patternsä¸­çš„æ‰€æœ‰å¥å­
        for pattern in patterns:
            if 'q' in pattern and 'a' in pattern:
                chinese_words = pattern['a'].split()
                if len(chinese_words) >= 2:
                    translation_items.append({
                        "type": "entozh",
                        "text": "å°†è‹±è¯­å¥å­ç¿»è¯‘æˆæ­£ç¡®çš„ä¸­æ–‡é¡ºåº",
                        "english": pattern['q'],
                        "scrambledChinese": chinese_words[1:] + [chinese_words[0]],
                        "correctChinese": chinese_words
                    })

        # å¦‚æœpatternsä¸è¶³ï¼Œè¡¥å……çŸ­è¯­
        if len(translation_items) < 4:
            for phrase in phrases[:4-len(translation_items)]:
                if 'en' in phrase and 'zh' in phrase:
                    chinese_words = phrase['zh'].split()
                    if len(chinese_words) >= 2:
                        translation_items.append({
                            "type": "entozh",
                            "text": "å°†è‹±è¯­å¥å­ç¿»è¯‘æˆæ­£ç¡®çš„ä¸­æ–‡é¡ºåº",
                            "english": phrase['en'],
                            "scrambledChinese": chinese_words[1:] + [chinese_words[0]],
                            "correctChinese": chinese_words
                        })

        return {
            "id": "en-to-zh",
            "title": "è‹±ç¿»ä¸­ç»ƒä¹ ",
            "steps": translation_items[:4],
            "reward": {"badge": "/images/rewards/translation-badge.png", "xp": 15}
        }

    def create_zh_to_en_quest(self, phrases: List[Dict], patterns: List[Dict]) -> Dict:
        """åˆ›å»ºä¸­ç¿»è‹±ç»ƒä¹  - ä¼˜å…ˆè¦†ç›–æ‰€æœ‰patterns"""
        translation_items = []

        # æ·»åŠ patternsä¸­çš„æ‰€æœ‰å¥å­
        for pattern in patterns:
            if 'q' in pattern and 'a' in pattern:
                english_words = pattern['q'].split()
                if len(english_words) >= 2:
                    translation_items.append({
                        "type": "zhtoen",
                        "text": "å°†ä¸­æ–‡å¥å­ç¿»è¯‘æˆæ­£ç¡®çš„è‹±æ–‡å•è¯é¡ºåº",
                        "chinese": pattern['a'],
                        "scrambledEnglish": english_words[1:] + [english_words[0]],
                        "correctEnglish": english_words
                    })

        # å¦‚æœpatternsä¸è¶³ï¼Œè¡¥å……çŸ­è¯­
        if len(translation_items) < 4:
            for phrase in phrases[:4-len(translation_items)]:
                if 'en' in phrase and 'zh' in phrase:
                    english_words = phrase['en'].split()
                    if len(english_words) >= 2:
                        translation_items.append({
                            "type": "zhtoen",
                            "text": "å°†ä¸­æ–‡å¥å­ç¿»è¯‘æˆæ­£ç¡®çš„è‹±æ–‡å•è¯é¡ºåº",
                            "chinese": phrase['zh'],
                            "scrambledEnglish": english_words[1:] + [english_words[0]],
                            "correctEnglish": english_words
                        })

        return {
            "id": "zh-to-en",
            "title": "ä¸­ç¿»è‹±ç»ƒä¹ ",
            "steps": translation_items[:4],
            "reward": {"badge": "/images/rewards/language-badge.png", "xp": 15}
        }

    def generate_complete_quests(self, module_data: Dict) -> List[Dict]:
        """ç”Ÿæˆå®Œæ•´çš„questsï¼Œç¡®ä¿patternsè¦†ç›–"""
        words = module_data.get('words', [])
        phrases = module_data.get('phrases', [])
        patterns = module_data.get('patterns', [])

        quests = []

        # 1. è¯è¯­é…å¯¹ç»ƒä¹  - æ€»æ˜¯ç”Ÿæˆ
        vocab_quest = self.create_vocabulary_matching_quest(words, phrases)
        quests.append(vocab_quest)

        # 2. è¯è¯­æ’åºç»ƒä¹  - æ€»æ˜¯ç”Ÿæˆ
        sorting_quest = self.create_sentence_sorting_quest(phrases, patterns)
        quests.append(sorting_quest)

        # 3. è‹±ç¿»ä¸­ç»ƒä¹  - ç¡®ä¿è¦†ç›–æ‰€æœ‰patternsï¼Œæ€»æ˜¯ç”Ÿæˆ
        en_to_zh_quest = self.create_en_to_zh_quest(phrases, patterns)
        quests.append(en_to_zh_quest)

        # 4. ä¸­ç¿»è‹±ç»ƒä¹  - ç¡®ä¿è¦†ç›–æ‰€æœ‰patternsï¼Œæ€»æ˜¯ç”Ÿæˆ
        zh_to_en_quest = self.create_zh_to_en_quest(phrases, patterns)
        quests.append(zh_to_en_quest)

        return quests

    def check_file_coverage(self, file_path: Path) -> Dict:
        """æ£€æŸ¥å•ä¸ªæ–‡ä»¶çš„patternsè¦†ç›–æƒ…å†µ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            file_name = file_path.name
            patterns = data.get('patterns', [])
            quests = data.get('quests', [])

            result = {
                'file_name': file_name,
                'has_patterns': len(patterns) > 0,
                'patterns_count': len(patterns),
                'quests_count': len(quests),
                'covered_patterns': 0,
                'missing_patterns': [],
                'needs_repair': False,
                'patterns': [],
                'quest_details': []
            }

            if not patterns:
                result['status'] = 'no_patterns'
                return result

            # æå–æ‰€æœ‰patterns
            all_patterns = set()
            for pattern in patterns:
                if 'q' in pattern and 'a' in pattern:
                    all_patterns.add((pattern['q'], pattern['a']))
                    result['patterns'].append({
                        'q': pattern['q'],
                        'a': pattern['a']
                    })

            # æå–å·²è¦†ç›–çš„patterns
            covered_patterns = self.extract_covered_patterns(quests)
            result['covered_patterns'] = len(covered_patterns)

            # æ‰¾å‡ºç¼ºå¤±çš„patterns
            missing_patterns = all_patterns - covered_patterns
            result['missing_patterns'] = [
                {'q': q, 'a': a} for q, a in missing_patterns
            ]

            # åˆ¤æ–­æ˜¯å¦éœ€è¦ä¿®å¤
            result['needs_repair'] = len(missing_patterns) > 0

            if len(missing_patterns) == 0:
                result['status'] = 'complete_coverage'
            else:
                result['status'] = 'incomplete_coverage'
                result['coverage_percentage'] = (len(covered_patterns) / len(all_patterns)) * 100

            # æ·»åŠ questsè¯¦æƒ…
            for quest in quests:
                result['quest_details'].append({
                    'id': quest.get('id'),
                    'title': quest.get('title'),
                    'steps_count': len(quest.get('steps', []))
                })

            return result

        except Exception as e:
            return {
                'file_name': file_path.name,
                'status': 'error',
                'error': str(e)
            }

    def repair_file(self, file_path: Path, dry_run: bool = False) -> Dict:
        """ä¿®å¤å•ä¸ªæ–‡ä»¶çš„quests"""
        check_result = self.check_file_coverage(file_path)

        if check_result.get('status') != 'incomplete_coverage':
            return {
                'file_name': file_path.name,
                'action': 'no_repair_needed',
                'reason': check_result.get('status', 'unknown')
            }

        if dry_run:
            return {
                'file_name': file_path.name,
                'action': 'would_repair',
                'missing_patterns': check_result['missing_patterns'],
                'coverage_percentage': check_result.get('coverage_percentage', 0)
            }

        try:
            # è¯»å–åŸæ–‡ä»¶
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # åˆ›å»ºå¤‡ä»½
            backup_path = file_path.with_suffix('.json.backup')
            with open(backup_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            # ç”Ÿæˆæ–°çš„quests
            new_quests = self.generate_complete_quests(data)
            data['quests'] = new_quests

            # ä¿å­˜ä¿®å¤åçš„æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            return {
                'file_name': file_path.name,
                'action': 'repaired',
                'old_quests_count': len(check_result['quest_details']),
                'new_quests_count': len(new_quests),
                'backup_created': str(backup_path)
            }

        except Exception as e:
            return {
                'file_name': file_path.name,
                'action': 'repair_failed',
                'error': str(e)
            }

    def check_all_files(self) -> Dict:
        """æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶"""
        json_files = list(self.content_dir.glob("*.json"))
        self.report['total_files'] = len(json_files)

        results = []

        logger.info(f"ğŸ” æ£€æŸ¥ {len(json_files)} ä¸ªJSONæ–‡ä»¶...")

        for file_path in json_files:
            result = self.check_file_coverage(file_path)
            results.append(result)

            if result['has_patterns']:
                self.report['files_with_patterns'] += 1

            if result['status'] == 'complete_coverage':
                self.report['files_with_complete_coverage'] += 1
            elif result['status'] == 'incomplete_coverage':
                self.report['files_needing_repair'] += 1

            # æ˜¾ç¤ºè¿›åº¦
            status_icon = {
                'complete_coverage': 'âœ…',
                'incomplete_coverage': 'âš ï¸',
                'no_patterns': 'âšª',
                'error': 'âŒ'
            }.get(result['status'], 'â“')

            logger.info(f"  {status_icon} {result['file_name']}: {result['status']}")

            if result['status'] == 'incomplete_coverage':
                coverage = result.get('coverage_percentage', 0)
                logger.info(f"    ğŸ“Š è¦†ç›–ç‡: {coverage:.1f}% ({result['covered_patterns']}/{result['patterns_count']})")

        self.report['details'] = results
        return self.report

    def repair_all_files(self, dry_run: bool = False) -> Dict:
        """ä¿®å¤æ‰€æœ‰éœ€è¦ä¿®å¤çš„æ–‡ä»¶"""
        if dry_run:
            logger.info("ğŸ” é¢„è§ˆæ¨¡å¼ - ä¸ä¼šå®é™…ä¿®æ”¹æ–‡ä»¶")

        # é¦–å…ˆæ£€æŸ¥æ‰€æœ‰æ–‡ä»¶
        check_report = self.check_all_files()

        repair_results = []
        files_to_repair = [r for r in check_report['details'] if r['needs_repair']]

        if not files_to_repair:
            logger.info("âœ… æ‰€æœ‰æ–‡ä»¶çš„patternséƒ½å·²å®Œå…¨è¦†ç›–ï¼Œæ— éœ€ä¿®å¤ï¼")
            return check_report

        logger.info(f"ğŸ”§ å‘ç° {len(files_to_repair)} ä¸ªæ–‡ä»¶éœ€è¦ä¿®å¤...")

        for result in files_to_repair:
            file_path = self.content_dir / result['file_name']
            repair_result = self.repair_file(file_path, dry_run)
            repair_results.append(repair_result)

            if repair_result['action'] == 'would_repair':
                logger.info(f"  ğŸ”„ {repair_result['file_name']}: å°†ä¿®å¤ (è¦†ç›–ç‡: {repair_result['coverage_percentage']:.1f}%)")
            elif repair_result['action'] == 'repaired':
                logger.info(f"  âœ… {repair_result['file_name']}: ä¿®å¤å®Œæˆ ({repair_result['old_quests_count']} â†’ {repair_result['new_quests_count']} quests)")
            elif repair_result['action'] == 'repair_failed':
                logger.error(f"  âŒ {repair_result['file_name']}: ä¿®å¤å¤±è´¥ - {repair_result['error']}")

        # æ·»åŠ ä¿®å¤ç»“æœåˆ°æŠ¥å‘Š
        check_report['repair_results'] = repair_results
        check_report['dry_run'] = dry_run

        return check_report

    def save_report(self, report: Dict, filename: str = None):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"pattern_coverage_report_{timestamp}.json"

        report_path = Path(filename)
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        logger.info(f"ğŸ“‹ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        return report_path

def main():
    parser = argparse.ArgumentParser(description="Quest Patternsè¦†ç›–æ£€æŸ¥å’Œä¿®å¤å·¥å…·")
    parser.add_argument("--content-dir", default="src/content", help="å†…å®¹ç›®å½•è·¯å¾„")
    parser.add_argument("--dry-run", action="store_true", help="é¢„è§ˆæ¨¡å¼ï¼Œåªæ£€æŸ¥ä¸ä¿®å¤")
    parser.add_argument("--output", help="æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶å")
    parser.add_argument("--save-report", action="store_true", help="ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶")

    args = parser.parse_args()

    content_dir = Path(args.content_dir)
    if not content_dir.exists():
        logger.error(f"âŒ å†…å®¹ç›®å½•ä¸å­˜åœ¨: {content_dir}")
        return 1

    logger.info("ğŸš€ å¼€å§‹Quest Patternsè¦†ç›–æ£€æŸ¥...")
    logger.info(f"ğŸ“ å†…å®¹ç›®å½•: {content_dir}")

    checker = PatternCoverageChecker(str(content_dir))

    if args.dry_run:
        logger.info("ğŸ” é¢„è§ˆæ¨¡å¼ - åªæ£€æŸ¥ä¸ä¿®å¤")

    # æ‰§è¡Œæ£€æŸ¥å’Œä¿®å¤
    report = checker.repair_all_files(dry_run=args.dry_run)

    # æ˜¾ç¤ºæ€»ç»“
    logger.info("\n" + "="*60)
    logger.info("ğŸ“Š æ£€æŸ¥å®Œæˆæ€»ç»“:")
    logger.info(f"   æ€»æ–‡ä»¶æ•°: {report['total_files']}")
    logger.info(f"   æœ‰patternsçš„æ–‡ä»¶: {report['files_with_patterns']}")
    logger.info(f"   å®Œå…¨è¦†ç›–çš„æ–‡ä»¶: {report['files_with_complete_coverage']}")
    logger.info(f"   éœ€è¦ä¿®å¤çš„æ–‡ä»¶: {report['files_needing_repair']}")

    if report['files_with_patterns'] > 0:
        coverage_rate = (report['files_with_complete_coverage'] / report['files_with_patterns']) * 100
        logger.info(f"   æ•´ä½“è¦†ç›–ç‡: {coverage_rate:.1f}%")

    if args.save_report or args.output:
        report_path = checker.save_report(report, args.output)

    logger.info("\nğŸ‰ æ£€æŸ¥å®Œæˆ!")
    return 0

if __name__ == "__main__":
    exit(main())